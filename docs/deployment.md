# éƒ¨ç½²è¯´æ˜æ–‡æ¡£

## ğŸ“‹ æœ€ä½ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚

#### æ¨èé…ç½®ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
- **GPU**: æ²æ›¦ C500 (64GB æ˜¾å­˜) æˆ– NVIDIA A100/H100
- **CPU**: 16 æ ¸å¿ƒæˆ–ä»¥ä¸Š
- **å†…å­˜**: 64GB RAM æˆ–ä»¥ä¸Š
- **å­˜å‚¨**: 200GB å¯ç”¨ç©ºé—´ï¼ˆSSD æ¨èï¼‰
- **ç½‘ç»œ**: å†…ç½‘ç¯å¢ƒå³å¯ï¼ˆæ”¯æŒå®Œå…¨ç¦»çº¿éƒ¨ç½²ï¼‰

#### æœ€ä½é…ç½®ï¼ˆæµ‹è¯•/å¼€å‘ç¯å¢ƒï¼‰
- **GPU**: NVIDIA RTX 3090 (24GB æ˜¾å­˜) æˆ–åŒç­‰ç®—åŠ›
- **CPU**: 8 æ ¸å¿ƒ
- **å†…å­˜**: 32GB RAM
- **å­˜å‚¨**: 100GB å¯ç”¨ç©ºé—´
- **ç½‘ç»œ**: å†…ç½‘ç¯å¢ƒå³å¯

### è½¯ä»¶è¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: 
  - Ubuntu 20.04 LTS æˆ–æ›´é«˜ç‰ˆæœ¬ï¼ˆæ¨èï¼‰
  - CentOS 8 æˆ–æ›´é«˜ç‰ˆæœ¬
  - Windows 10/11 with WSL2ï¼ˆéƒ¨åˆ†åŠŸèƒ½å—é™ï¼‰
  
- **Python**: 3.10, 3.11, 3.12
  
- **CUDA**: 11.8 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼ˆNVIDIA GPUï¼‰
  
- **Docker**: 20.10 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼ˆå¯é€‰ï¼Œç”¨äºå®¹å™¨åŒ–éƒ¨ç½²ï¼‰

## ğŸš€ ä¸€æ­¥æ­¥éƒ¨ç½²æŒ‡å—

### æ–¹æ¡ˆä¸€ï¼šæ ‡å‡†éƒ¨ç½²ï¼ˆæ¨èï¼‰

#### æ­¥éª¤ 1: ç³»ç»Ÿç¯å¢ƒå‡†å¤‡

```bash
# æ›´æ–°ç³»ç»ŸåŒ…
sudo apt update && sudo apt upgrade -y

# å®‰è£…åŸºç¡€å·¥å…·
sudo apt install -y git wget curl build-essential

# å®‰è£… Python 3.10+
sudo apt install -y python3.10 python3.10-venv python3-pip

# éªŒè¯å®‰è£…
python3 --version  # åº”æ˜¾ç¤º Python 3.10.x æˆ–æ›´é«˜
```

#### æ­¥éª¤ 2: å…‹éš†é¡¹ç›®ä»“åº“

```bash
# å…‹éš†ä»“åº“åˆ°æœ¬åœ°
git clone https://github.com/Xcoconut114514/RustSentinel-of-ShanghaiOpen.git

# è¿›å…¥é¡¹ç›®ç›®å½•
cd RustSentinel-of-ShanghaiOpen
```

#### æ­¥éª¤ 3: åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# åˆ›å»º Python è™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate  # Linux/macOS
# æˆ–
.\venv\Scripts\activate   # Windows
```

#### æ­¥éª¤ 4: å®‰è£…ä¾èµ–

```bash
# å‡çº§ pip
pip install --upgrade pip

# å®‰è£…é¡¹ç›®ä¾èµ–
pip install -r requirements.txt

# éªŒè¯å®‰è£…
pip list | grep -E "openai|gradio|vllm"
```

#### æ­¥éª¤ 5: ä¸‹è½½æ¨¡å‹æ–‡ä»¶

**æ–¹æ³• A: ä½¿ç”¨ HuggingFaceï¼ˆå›½å¤–ç”¨æˆ·ï¼‰**

```bash
# å®‰è£… HuggingFace CLI
pip install -U huggingface_hub

# ç™»å½•ï¼ˆå¯é€‰ï¼Œå…¬å¼€æ¨¡å‹ä¸éœ€è¦ï¼‰
huggingface-cli login

# ä¸‹è½½æ¨¡å‹
huggingface-cli download deepseek-ai/DeepSeek-R1-Distill-Qwen-7B \
    --local-dir ./models/deepseek-r1-distill
```

**æ–¹æ³• B: ä½¿ç”¨ ModelScopeï¼ˆå›½å†…æ¨èï¼‰**

```bash
# å®‰è£… ModelScope
pip install modelscope

# ä¸‹è½½æ¨¡å‹
python -c "
from modelscope import snapshot_download
model_dir = snapshot_download(
    'deepseek-ai/DeepSeek-R1-Distill-Qwen-7B',
    cache_dir='./models'
)
print(f'æ¨¡å‹å·²ä¸‹è½½åˆ°: {model_dir}')
"
```

**æ–¹æ³• C: æ‰‹åŠ¨ä¸‹è½½**

1. è®¿é—® [DeepSeek-R1 æ¨¡å‹é¡µé¢](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B)
2. ä¸‹è½½æ‰€æœ‰æ¨¡å‹æ–‡ä»¶åˆ° `./models/deepseek-r1-distill/` ç›®å½•
3. ç¡®ä¿ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š
   ```
   models/
   â””â”€â”€ deepseek-r1-distill/
       â”œâ”€â”€ config.json
       â”œâ”€â”€ tokenizer.json
       â”œâ”€â”€ model.safetensors
       â””â”€â”€ ...
   ```

#### æ­¥éª¤ 6: é…ç½®ç¯å¢ƒå˜é‡

```bash
# åˆ›å»ºé…ç½®æ–‡ä»¶
cp config/example.env config/.env

# ç¼–è¾‘é…ç½®æ–‡ä»¶
nano config/.env
```

åœ¨ `.env` æ–‡ä»¶ä¸­è®¾ç½®ï¼š

```bash
# æ¨¡å‹è·¯å¾„
MODEL_PATH=./models/deepseek-r1-distill

# vLLM æœåŠ¡é…ç½®
VLLM_HOST=0.0.0.0
VLLM_PORT=8000

# Web ç•Œé¢é…ç½®
WEB_HOST=0.0.0.0
WEB_PORT=8501

# GPU é…ç½®
GPU_MEMORY_UTILIZATION=0.9
TENSOR_PARALLEL_SIZE=1
```

#### æ­¥éª¤ 7: å¯åŠ¨æ¨ç†å¼•æ“

åœ¨ç¬¬ä¸€ä¸ªç»ˆç«¯çª—å£ä¸­å¯åŠ¨ vLLM æœåŠ¡ï¼š

```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# å¯åŠ¨ vLLMï¼ˆåŸºç¡€é…ç½®ï¼‰
vllm serve ./models/deepseek-r1-distill \
    --dtype bfloat16 \
    --port 8000 \
    --gpu-memory-utilization 0.9 \
    --model-name deepseek-audit

# æˆ–ä½¿ç”¨å®Œæ•´é…ç½®
vllm serve ./models/deepseek-r1-distill \
    --dtype bfloat16 \
    --port 8000 \
    --host 0.0.0.0 \
    --gpu-memory-utilization 0.9 \
    --model-name deepseek-audit \
    --max-model-len 8192 \
    --trust-remote-code
```

ç­‰å¾…çœ‹åˆ°ä»¥ä¸‹è¾“å‡ºè¡¨ç¤ºå¯åŠ¨æˆåŠŸï¼š
```
INFO:     Started server process
INFO:     Uvicorn running on http://0.0.0.0:8000
```

#### æ­¥éª¤ 8: å¯åŠ¨ Web ç•Œé¢

åœ¨ç¬¬äºŒä¸ªç»ˆç«¯çª—å£ä¸­å¯åŠ¨ Gradio ç•Œé¢ï¼š

```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# è¿›å…¥æºç ç›®å½•
cd src

# å¯åŠ¨ Gradio åº”ç”¨
python app_gradio.py
```

æˆåŠŸå¯åŠ¨åï¼Œè®¿é—®ï¼š
- **æœ¬åœ°è®¿é—®**: http://localhost:8501
- **å±€åŸŸç½‘è®¿é—®**: http://YOUR_IP:8501

### æ–¹æ¡ˆäºŒï¼šDocker éƒ¨ç½²

#### æ­¥éª¤ 1: å®‰è£… Docker å’Œ NVIDIA Container Toolkit

```bash
# å®‰è£… Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# å®‰è£… NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
    sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

#### æ­¥éª¤ 2: æ„å»º Docker é•œåƒ

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/Xcoconut114514/RustSentinel-of-ShanghaiOpen.git
cd RustSentinel-of-ShanghaiOpen

# æ„å»ºé•œåƒ
docker build -t rustsentinel:latest -f docker/Dockerfile .
```

#### æ­¥éª¤ 3: è¿è¡Œå®¹å™¨

```bash
# è¿è¡Œå®¹å™¨ï¼ˆå‰å°ï¼‰
docker run --rm \
    --gpus all \
    -p 8000:8000 \
    -p 8501:8501 \
    -v $(pwd)/models:/app/models \
    rustsentinel:latest

# æˆ–åå°è¿è¡Œ
docker run -d \
    --name rustsentinel \
    --gpus all \
    -p 8000:8000 \
    -p 8501:8501 \
    -v $(pwd)/models:/app/models \
    --restart unless-stopped \
    rustsentinel:latest

# æŸ¥çœ‹æ—¥å¿—
docker logs -f rustsentinel
```

### æ–¹æ¡ˆä¸‰ï¼šç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼ˆKubernetesï¼‰

è¯¦ç»†é…ç½®è¯·å‚è€ƒ [docker/k8s-deployment.yaml](../docker/k8s-deployment.yaml)

## ğŸ”§ ç¯å¢ƒå˜é‡é…ç½®

### å¿…éœ€é…ç½®

| å˜é‡å | è¯´æ˜ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|--------|------|--------|------|
| `MODEL_PATH` | æ¨¡å‹æ–‡ä»¶è·¯å¾„ | `./models/deepseek-r1-distill` | `/data/models/deepseek` |
| `VLLM_PORT` | vLLM æœåŠ¡ç«¯å£ | `8000` | `8000` |
| `WEB_PORT` | Web ç•Œé¢ç«¯å£ | `8501` | `8501` |

### å¯é€‰é…ç½®

| å˜é‡å | è¯´æ˜ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|--------|------|--------|------|
| `GPU_MEMORY_UTILIZATION` | GPU æ˜¾å­˜åˆ©ç”¨ç‡ | `0.9` | `0.8` |
| `MAX_MODEL_LEN` | æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ | `8192` | `16384` |
| `TENSOR_PARALLEL_SIZE` | å¼ é‡å¹¶è¡Œæ•° | `1` | `2` |
| `DTYPE` | æ•°æ®ç±»å‹ | `bfloat16` | `float16` |

### é«˜çº§é…ç½®

```bash
# å¯ç”¨é‡åŒ–ï¼ˆå‡å°‘æ˜¾å­˜å ç”¨ï¼‰
QUANTIZATION=awq

# å¯ç”¨ Flash Attention 2ï¼ˆåŠ é€Ÿæ¨ç†ï¼‰
ENABLE_FLASH_ATTN=true

# è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯è·¯å¾„
SYSTEM_PROMPT_PATH=./config/custom_prompt.txt

# æ—¥å¿—çº§åˆ«
LOG_LEVEL=INFO
```

## â“ å¸¸è§é—®é¢˜è§£ç­” (FAQ)

### Q1: å¯åŠ¨ vLLM æ—¶æç¤ºæ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**A**: å°è¯•ä»¥ä¸‹è§£å†³æ–¹æ¡ˆï¼š

1. **é™ä½æ˜¾å­˜åˆ©ç”¨ç‡**:
   ```bash
   vllm serve ... --gpu-memory-utilization 0.7
   ```

2. **ä½¿ç”¨é‡åŒ–æ¨¡å‹**:
   ```bash
   vllm serve ... --quantization awq
   ```

3. **å‡å°‘æœ€å¤§åºåˆ—é•¿åº¦**:
   ```bash
   vllm serve ... --max-model-len 4096
   ```

4. **ä½¿ç”¨å¤š GPU å¹¶è¡Œ**:
   ```bash
   vllm serve ... --tensor-parallel-size 2
   ```

### Q2: Web ç•Œé¢æ— æ³•è®¿é—®æ€ä¹ˆåŠï¼Ÿ

**A**: æ£€æŸ¥ä»¥ä¸‹äº‹é¡¹ï¼š

1. **ç¡®è®¤æœåŠ¡å·²å¯åŠ¨**:
   ```bash
   ps aux | grep "app_gradio"
   netstat -tuln | grep 8501
   ```

2. **æ£€æŸ¥é˜²ç«å¢™è§„åˆ™**:
   ```bash
   sudo ufw allow 8501/tcp
   ```

3. **ä¿®æ”¹ç›‘å¬åœ°å€**:
   åœ¨ `src/app_gradio.py` ä¸­ç¡®ä¿ï¼š
   ```python
   demo.launch(server_name="0.0.0.0", server_port=8501)
   ```

### Q3: æ¨¡å‹ä¸‹è½½é€Ÿåº¦æ…¢æˆ–å¤±è´¥ï¼Ÿ

**A**: ä½¿ç”¨å›½å†…é•œåƒï¼š

```bash
# è®¾ç½® HuggingFace é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–ä½¿ç”¨ ModelScope
pip install modelscope
python -c "from modelscope import snapshot_download; snapshot_download('deepseek-ai/DeepSeek-R1-Distill-Qwen-7B')"
```

### Q4: å¦‚ä½•åœ¨æ²¡æœ‰ GPU çš„ç¯å¢ƒä¸‹è¿è¡Œï¼Ÿ

**A**: ä¸æ¨è CPU éƒ¨ç½²ï¼ˆé€Ÿåº¦ææ…¢ï¼‰ï¼Œä½†å¯ä»¥ï¼š

```bash
# ä½¿ç”¨ CPU æ¨¡å¼ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰
vllm serve ./models/deepseek-r1-distill \
    --device cpu \
    --dtype float32
```

æˆ–è€ƒè™‘ä½¿ç”¨äº‘ç«¯ GPU æœåŠ¡ã€‚

### Q5: å¦‚ä½•æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬ï¼Ÿ

**A**: æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
cd RustSentinel-of-ShanghaiOpen
git pull origin main
source venv/bin/activate
pip install -r requirements.txt --upgrade
```

### Q6: å¯ä»¥åŒæ—¶å®¡è®¡å¤šä¸ªæ–‡ä»¶å—ï¼Ÿ

**A**: å½“å‰ç‰ˆæœ¬ä¸»è¦æ”¯æŒå•æ–‡ä»¶å®¡è®¡ã€‚æ‰¹é‡å®¡è®¡åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ï¼Œæ‚¨å¯ä»¥ï¼š

1. ç¼–å†™è„šæœ¬å¾ªç¯è°ƒç”¨ API
2. ä½¿ç”¨ `examples/batch_audit.py`ï¼ˆå³å°†æ¨å‡ºï¼‰
3. å…³æ³¨é¡¹ç›®æ›´æ–°

### Q7: å¦‚ä½•è‡ªå®šä¹‰å®¡è®¡è§„åˆ™ï¼Ÿ

**A**: ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯ï¼š

1. ç¼–è¾‘ `config/system_prompt.txt`
2. æ·»åŠ è‡ªå®šä¹‰æ£€æµ‹è§„åˆ™ï¼Œä¾‹å¦‚ï¼š
   ```
   é‡ç‚¹æ£€æµ‹ä»¥ä¸‹æ¼æ´ç±»å‹ï¼š
   1. Signer æ£€æŸ¥ç¼ºå¤±
   2. è´¦æˆ·æ‰€æœ‰æƒéªŒè¯ç¼ºå¤±
   3. æ•´æ•°æº¢å‡º/ä¸‹æº¢
   4. é‡å…¥æ”»å‡»
   5. [ä½ çš„è‡ªå®šä¹‰è§„åˆ™]
   ```
3. é‡å¯æœåŠ¡ç”Ÿæ•ˆ

### Q8: éƒ¨ç½²åœ¨äº‘æœåŠ¡å™¨ä¸Šï¼Œå¦‚ä½•ä¿è¯å®‰å…¨ï¼Ÿ

**A**: å»ºè®®æªæ–½ï¼š

1. **ä½¿ç”¨ VPN/SSH éš§é“**:
   ```bash
   ssh -L 8501:localhost:8501 user@server
   ```

2. **å¯ç”¨èº«ä»½éªŒè¯**ï¼ˆåœ¨ Gradio ä¸­ï¼‰:
   ```python
   demo.launch(auth=("admin", "your_password"))
   ```

3. **é…ç½®é˜²ç«å¢™**ï¼Œä»…å…è®¸å†…ç½‘è®¿é—®

4. **ä½¿ç”¨ HTTPS**ï¼ˆé…åˆ Nginx åå‘ä»£ç†ï¼‰

### Q9: å¦‚ä½•æŸ¥çœ‹è¯¦ç»†æ—¥å¿—ï¼Ÿ

**A**: å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼š

```bash
# å¯åŠ¨ vLLM æ—¶
vllm serve ... --log-level DEBUG

# å¯åŠ¨ Gradio æ—¶
LOG_LEVEL=DEBUG python src/app_gradio.py
```

### Q10: æ”¯æŒå“ªäº› Rust æ¡†æ¶çš„å®¡è®¡ï¼Ÿ

**A**: å½“å‰ä¸»è¦æ”¯æŒï¼š

- âœ… Anchor Framework (Solana)
- âœ… åŸç”Ÿ Solana ç¨‹åº
- ğŸš§ Substrate (è®¡åˆ’ä¸­)
- ğŸš§ Move (è®¡åˆ’ä¸­)

## ğŸ”— ç›¸å…³é“¾æ¥

- [ä¸»æ–‡æ¡£](../README.md)
- [æŠ€æœ¯æ¶æ„](architecture.md)
- [ä½¿ç”¨ç¤ºä¾‹](../examples/)
- [é—®é¢˜åé¦ˆ](https://github.com/Xcoconut114514/RustSentinel-of-ShanghaiOpen/issues)

---

å¦‚æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒï¼š2819404727@qq.com
